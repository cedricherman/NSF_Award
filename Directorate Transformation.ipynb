{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "For this project there are 3 parameters of interest:\n",
    "    * Abstract\n",
    "    * Award Type (aka Award Instrumentation)\n",
    "    * Directorate Name\n",
    "\n",
    "Abstracts were saved in its own CSV file while Award type and Directorate Name were in the same CSV file.\n",
    "\n",
    "Missing data were discarded, award types were consolidated into 4 groups and Directorate names had abbreviation. All text had to be lower case and so on.\n",
    "Dedicated python module were created for each of those 3 parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is the python module for Directorate name transformation prior to processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Nov  8 23:52:41 2017\n",
    "\n",
    "@author: herma\n",
    "\n",
    "There are 7 directorates in the NSF Organization\n",
    "Each directorate has multiple division.\n",
    "\n",
    "There is also a number of offices which we will group together \n",
    "and treat them at the same level as directorate\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# import to read and filter data\n",
    "import pandas as pd\n",
    "import re\n",
    "import itertools\n",
    "from sklearn.feature_extraction import stop_words\n",
    "\n",
    "    \n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    remove punctuations and stop words for further processing\n",
    "    \"\"\"\n",
    "    if type(text) is str:\n",
    "        # split text on alphanumeric characters only\n",
    "        text_tokens = re.findall('\\w+', text)\n",
    "        # remove stopwords\n",
    "        text_tokens_sw = [s for s in text_tokens if s not in stop_words.ENGLISH_STOP_WORDS]\n",
    "        # reunite text\n",
    "        return' '.join(text_tokens_sw)\n",
    "    else:\n",
    "        return text\n",
    "    \n",
    "def are_letters_common(abbr, full_word):\n",
    "    \"\"\"\n",
    "    returns true if all letters in abbreaviation are present in full word\n",
    "    \"\"\"\n",
    "    # check if all letters are in full_word\n",
    "    for l in list(abbr):\n",
    "        if l not in full_word:\n",
    "            return False\n",
    "    # true if loop completed (all letters in full)\n",
    "    return True\n",
    "    \n",
    "def find_abbreviations(ValCount_dict):\n",
    "    \"\"\"\n",
    "    make pairs of abbreviated, non-abbreviated names\n",
    "    \"\"\"\n",
    "    # make two lists: abbrevation list and replacement list\n",
    "    abbreviation = []\n",
    "    replacement = []\n",
    "    # group dict by value\n",
    "    for w_cnt in range(min(ValCount_dict.values()), max(ValCount_dict.values())+1):\n",
    "        # make a list of keys which have the same count\n",
    "        list4pairs = [kp.split() for kp,vp in ValCount_dict.items() if vp == w_cnt]\n",
    "        # make a list of pair combinations\n",
    "        pairs = list(itertools.combinations(list4pairs , 2))\n",
    "        # compare pairs\n",
    "        for p in pairs:\n",
    "            abbre_list =[]\n",
    "            repl_list = []\n",
    "            # compare word by word\n",
    "            for w in range(w_cnt):\n",
    "                # get abbreviated word and longer word (full)\n",
    "                if len(p[0][w]) >=  len(p[1][w]):\n",
    "#                   wlen = len(p[1][w])\n",
    "                    abbre_word = p[1][w]\n",
    "                    full_word = p[0][w]\n",
    "                else:\n",
    "#                   wlen = len(p[0][w])\n",
    "                    abbre_word = p[0][w]\n",
    "                    full_word = p[1][w]\n",
    "                # do they have the same root?\n",
    "    #           if abbre_word == full_word[:wlen]:\n",
    "                # test if all letters in abbre_word are in full_word\n",
    "                if are_letters_common(abbre_word,full_word):\n",
    "                    abbre_list.append(abbre_word)\n",
    "                    repl_list.append(full_word)\n",
    "                else:\n",
    "                    # root is different, move on\n",
    "                    # decrement w to indicate loop ended with a break statement\n",
    "                    w -= 1\n",
    "                    break\n",
    "            # if for loop complete, concatenate word list\n",
    "            if w == w_cnt-1:\n",
    "                abbreviation.append(' '.join(abbre_list))\n",
    "                replacement.append(' '.join(repl_list))\n",
    "    # return two list\n",
    "    return abbreviation,replacement\n",
    "\n",
    "\n",
    "def get_Directorate(filename):\n",
    "    \"\"\"\n",
    "    return consolidated directorate names records\n",
    "    \"\"\"\n",
    "    # read database (csv file)\n",
    "    df_core = pd.read_csv(filename,header=0, encoding = 'utf-8')\n",
    "    # Take care of directorate\n",
    "    # set string to lower case, NOTE: lambda must have if AND else statement\n",
    "    # HAVE TO LOWER TEXT FIRST TO REMOVE STOP WORDS LATER!!!!!\n",
    "    df_core.Directorate_Name= df_core.Directorate_Name.str.lower()\n",
    "    df_core.Directorate_Name = df_core.Directorate_Name.apply(clean_text)\n",
    "    # merge abbreviations\n",
    "    # get all possible directorate name\n",
    "    df_directValCount = df_core.Directorate_Name.value_counts()\n",
    "    # create directorate dict, value is name length\n",
    "    Directorate_lendict = {u: len(u.split()) for u in df_directValCount.index}\n",
    "    # figure out directorate name that matches non abrreviated name\n",
    "    abbreviation, replacement = find_abbreviations(Directorate_lendict)\n",
    "    # replace each abbreaviation by full name\n",
    "    df_core.Directorate_Name.replace(to_replace=abbreviation, value=replacement,\\\n",
    "                                     inplace=True, method='pad')\n",
    "    # merge all offices together and treat it as one directorate\n",
    "#    df_core.Directorate_Name = \\\n",
    "#        df_core.Directorate_Name.apply(lambda x: 'office'\\\n",
    "#                                        if type(x) is str and 'office' in x else x )\n",
    "    # remove all nan records\n",
    "    df_core.dropna(subset=['Directorate_Name'], inplace=True )\n",
    "    \n",
    "    # removes all office!\n",
    "    df_core = df_core[ ~df_core.Directorate_Name.str.contains('office',\\\n",
    "                                                     case=False)]\n",
    "    \n",
    "    # returns pandas data frame\n",
    "    return df_core.iloc[:, df_core.columns.get_indexer(\\\n",
    "                                                    ['AwardID', 'Directorate_Name'])] \n",
    "\n",
    "#### The Main program, can be used as a script or as a module\n",
    "if __name__ == \"__main__\":\n",
    "    # get entire corpus\n",
    "    directorate = get_Directorate('../DB_1960_to_2017.csv')\n",
    "    print( directorate.count() )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
